{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e0fea0-8697-4c6e-a840-948cff36c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyNeuroML >>> 03:01:51 - INFO - Loading NeuroML2 file: ../grc_lemsDefinitions/IaF_GrC.nml\n",
      "pyNeuroML >>> 03:01:51 - INFO - Executing: (java -Xmx400M  -jar  \"/opt/anaconda3/envs/neuroml/lib/python3.13/site-packages/pyneuroml/utils/./../lib/jNeuroML-0.14.0-jar-with-dependencies.jar\" -validate tempdata/pure_network_3.net.nml ) in directory: .\n",
      "pyNeuroML >>> 03:01:51 - INFO - Command completed successfully!\n",
      "pyNeuroML >>> 03:01:51 - INFO - Executing: (java -Xmx400M  -jar  \"/opt/anaconda3/envs/neuroml/lib/python3.13/site-packages/pyneuroml/utils/./../lib/jNeuroML-0.14.0-jar-with-dependencies.jar\" -validate tempdata/pure_network_3.net.nml ) in directory: .\n",
      "pyNeuroML >>> 03:01:52 - INFO - Command completed successfully!\n",
      "pyNeuroML >>> 03:01:52 - INFO - Output: \n",
      "  jNeuroML >>   jNeuroML v0.14.0\n",
      "  jNeuroML >>  Validating: /Users/laviniatakarabe/Desktop/updated_version/biophysical_model/tempdata/pure_network_3.net.nml\n",
      "  jNeuroML >>  Valid against schema and all tests\n",
      "  jNeuroML >>  No warnings\n",
      "  jNeuroML >>  \n",
      "  jNeuroML >>  Validated 1 files: All valid and no warnings\n",
      "  jNeuroML >>  \n",
      "  jNeuroML >>  \n",
      "pyNeuroML >>> 03:01:52 - INFO - Successfully ran the following command using pyNeuroML v1.3.15: \n",
      "    java -Xmx400M  -jar  \"/opt/anaconda3/envs/neuroml/lib/python3.13/site-packages/pyneuroml/utils/./../lib/jNeuroML-0.14.0-jar-with-dependencies.jar\" -validate tempdata/pure_network_3.net.nml \n",
      "pyNeuroML >>> 03:01:52 - INFO - Output:\n",
      "\n",
      " jNeuroML v0.14.0\n",
      "Validating: /Users/laviniatakarabe/Desktop/updated_version/biophysical_model/tempdata/pure_network_3.net.nml\n",
      "Valid against schema and all tests\n",
      "No warnings\n",
      "\n",
      "Validated 1 files: All valid and no warnings\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network built and validated using SpikeGenerator components.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import neuroml as nml\n",
    "from pyneuroml import pynml\n",
    "\n",
    "\n",
    "from neuroml import SpikeGeneratorRefPoisson\n",
    "\n",
    "# === Simulation parameters ===\n",
    "runID = '3'\n",
    "duration = 180  # ms\n",
    "dt = 0.05        # ms\n",
    "minimumISI = 2  # ms\n",
    "ONRate = 50     # Hz\n",
    "OFFRate = 0     # Hz\n",
    "\n",
    "base_dir = 'tempdata'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# === Load parameters ===\n",
    "with open('../params_file.pkl', 'rb') as file:\n",
    "    params = pkl.load(file)\n",
    "\n",
    "N_syn = params['N_syn'][int(runID) - 1]\n",
    "f_mf = params['f_mf'][int(runID) - 1]\n",
    "run_num = params['run_num'][int(runID) - 1]\n",
    "\n",
    "# === Load connectivity matrix ===\n",
    "conn_file = f'network_structures/GCLconnectivity_{N_syn}.pkl'\n",
    "with open(conn_file, 'rb') as file:\n",
    "    conn_data = pkl.load(file)\n",
    "\n",
    "conn_mat = conn_data['conn_mat']\n",
    "N_mf, N_grc = conn_mat.shape\n",
    "\n",
    "assert np.all(conn_mat.sum(axis=0) == N_syn), 'Invalid connectivity matrix'\n",
    "\n",
    "# === Split MFs into ON and OFF ===\n",
    "N_mf_ON = int(N_mf * f_mf)\n",
    "mf_indices_ON = sorted(random.sample(range(N_mf), N_mf_ON))\n",
    "mf_indices_OFF = sorted(set(range(N_mf)) - set(mf_indices_ON))\n",
    "\n",
    "# === Load GrC cell model and synapses ===\n",
    "iaf_file = f\"../grc_lemsDefinitions/IaF_GrC.nml\"\n",
    "ampa_file = f\"../grc_lemsDefinitions/RothmanMFToGrCAMPA_{N_syn}.xml\"\n",
    "nmda_file = f\"../grc_lemsDefinitions/RothmanMFToGrCNMDA_{N_syn}.xml\"\n",
    "\n",
    "doc = nml.NeuroMLDocument(id=\"GCL_Network\")\n",
    "net = nml.Network(id=\"gcl_net\")\n",
    "doc.networks.append(net)\n",
    "\n",
    "# === Add GrC population ===\n",
    "grc_cell = pynml.read_neuroml2_file(iaf_file).iaf_ref_cells[0]\n",
    "GrCPop = nml.Population(id=\"GrCPop\", component=grc_cell.id, size=N_grc)\n",
    "net.populations.append(GrCPop)\n",
    "\n",
    "# === Add ON spike generators ===\n",
    "pop = SpikeGeneratorRefPoisson(f\"mfONPop\", ONRate, minimumISI, size=N_mf_ON)\n",
    "\n",
    "# === Add OFF spike generators ===\n",
    "pop = SpikeGeneratorRefPoisson(f\"mfOFFPop\", OFFRate, minimumISI, size=N_mf-N_mf_ON)\n",
    "\n",
    "# === Add synaptic connections ===\n",
    "syns = [\n",
    "    pynml.read_lems_file(ampa_file).components['RothmanMFToGrCAMPA'].id,\n",
    "    pynml.read_lems_file(nmda_file).components['RothmanMFToGrCNMDA'].id\n",
    "]\n",
    "\n",
    "for ix_on, mf_ix in enumerate(mf_indices_ON):\n",
    "    for grc_ix in np.where(conn_mat[mf_ix, :] == 1)[0]:\n",
    "        for syn in syns:\n",
    "            net.synaptic_connections.append(nml.SynapticConnection(\n",
    "                from_=f\"mfONPop[{ix_on}]\",\n",
    "                to=f\"GrCPop[{grc_ix}]\",\n",
    "                synapse=syn))\n",
    "\n",
    "for ix_off, mf_ix in enumerate(mf_indices_OFF):\n",
    "    for grc_ix in np.where(conn_mat[mf_ix, :] == 1)[0]:\n",
    "        for syn in syns:\n",
    "            net.synaptic_connections.append(nml.SynapticConnection(\n",
    "                from_=f\"mfOFFPop[{ix_off}]\",\n",
    "                to=f\"GrCPop[{grc_ix}]\",\n",
    "                synapse=syn))\n",
    "\n",
    "# === Save and run ===\n",
    "net_file = os.path.join(base_dir, f'pure_network_{runID}.net.nml')\n",
    "doc.includes.append(nml.IncludeType(href=os.path.basename(iaf_file)))\n",
    "#doc.includes.append(nml.IncludeType(href=os.path.basename(ampa_file)))\n",
    "#doc.includes.append(nml.IncludeType(href=os.path.basename(nmda_file)))\n",
    "pynml.write_neuroml2_file(doc, net_file)\n",
    "pynml.validate_neuroml2(net_file)\n",
    "\n",
    "print(\"Network built and validated using SpikeGenerator components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cda73-04ae-49ac-b9db-0f6fc5d8cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyneuroml.lems.LEMSSimulation import LEMSSimulation\n",
    "\n",
    "sim_id = f\"sim_{runID}\"\n",
    "net_file_name = os.path.basename(net_file)\n",
    "sim = LEMSSimulation(sim_id, net.id, net_file_name)\n",
    "sim.set_simulation_properties(\n",
    "    duration=duration,\n",
    "    dt=dt,\n",
    "    target=net.id,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Record all membrane potentials\n",
    "sim.save_all_v()\n",
    "\n",
    "# Save simulation file\n",
    "lems_file = os.path.join(base_dir, f\"{sim_id}.xml\")\n",
    "sim.create_lems_file(lems_file)\n",
    "\n",
    "print(f\"LEMS simulation file written to: {lems_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d205e-9b8e-4162-8e43-f2a64d268396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
